# 面试问题串讲

### 1、linux中常用高级命令

```
top：查看内存
ps -ef: 查看进程
netstat -tunlp | grep 进程名：查看端口
df -h: 查看磁盘
tar: 解压
rpm: 安装
```

### 2、shell中单双引号

```
单引号不解析
双引号解析
例子:
"$do_date" 2020-08-19
'$do_date' $do_date
'"$do_date"' "$do_date"
"'$do_date'" '2020-08-19'
```

### 3、简单的启动脚本

```
#!/bin/bash
case $1 in
"start")
	for i in hadoop102 hadoop103 hadoop104
	do 
		ssh $i "执行命令1"
	done
;;
"stop")
	for i in hadoop102 hadoop103 hadoop104
	do 
		ssh $i "执行命令2"
	done
;;
esac
```

### 4、导入导出脚本：

```
!#/bin/bash
sqoop import
--connect 
--username
--password
--target-dir
--delete-target-dir
--fields-terminated-by
--query "$2" 'and $CONDITIONS;'
--null-string '\\N'
--null-non-string '\\N'
```

### 5、数仓执行脚本

```

```

### 6、hadoop常用端口

| 类型/版本       | 2.0       | 3.0       |
| --------------- | --------- | --------- |
| web访问hdfs端口 | 50070     | 9870      |
| mr任务查看      | 8080      | 8080      |
| 历史任务查看    | 19888     | 19888     |
| hdfs客户端      | 8020/9000 | 8020/9000 |

### 7、配置文件相关

| 作用/版本 | 2.0                      | 3.0                      |
| --------- | ------------------------ | ------------------------ |
| 核心配置  | core-site.xml            | core-site.xml            |
| hdfs配置  | hdfs-site.xml            | hdfs-site.xml            |
| mr配置    | mapred-site.xml          | mapred-site.xml          |
| yarn配置  | yarn-site.xml            | yarn.site.xml            |
| 节点文件  | slaves                   | workers                  |
| 环境变量  | /etc/profile.d/my_env.sh | /etc/profile.d/my_env.sh |

### 8、写流程：

### 9、小文件危害及处理

```
危害：
1、一个文件会维护一个150字节的元数据，小文件过多会浪费namenode存储资源
2、提交mr任务时是对一个文件进行单独切片，每一个切片会启动一个maptask,小文件过多会使map数量过多，浪费集群资源

处理：
1、har归档：
单个：hadoop archive -archiveName 419.har -p /fc/src/20120116/ 419 /user/heipark
多个：hadoop archive -archiveName combine.har -p /fc/src/20120116/ 419 512 334 /user/heipark

2、combinetextinputformat：合并到一起统一切片
3、jvm重用：一般10个

```

### 10、shuffle及其优化

### 11、yarn工作机制

### 12、yarn调度器介绍

```
FIFO、容量、公平

FIFO：基本不用，先进先出
容量调度器：apache默认：多队列，某一个队列资源不够可以向其他队列借资源
公平调度器：cdh默认：多队列，每个任务公平享有队列资源，并发度高

调度器选择：并发要求高的使用公平，要求不高时使用容量

多队列的分配：
按业务线：下单、支付、添加收藏
按框架：hive，spark，flink

多队列的好处：防止某个错误导致全业务崩溃
```

### 13、zk的选举

```
半数机制，集群选择奇数台
```

### 14、zk常用命令

```
ls:查看目录下所有文件
get:获取znode的值
create:创建znode
delete：删除znode

znode分类：
临时或者永久  有编号无编号  分成4类
```

### 15、zk安装台数

```
10 3
20 5
50 7
100 11

说明：台数越多可靠性提高，通信性能下降
```

### 16、flume的组成

```
source：
taildir :
1、多目录，断点续传 Apache1.7 cdh1.6产生
2、挂掉可能会造成数据重复，下游hive dwd层group by去重，redis去重，bloom过滤器，sparkStream去重，
3、文件递归读取：可以分解成递归获取文件 + taildir读取

channel:
1、file channel:可靠性最好，但是性能较低，默认100万个event
2、memory channel：可靠性低，但是性能较高，普通日志使用，默认100个event可能会丢这么多
3、kafka channel：下游是kafka时可以使用，速度大于 memory channel + flume sink
1.6以前会有header + 内容这样的脏数据，1.7解决了

sink:
1、小文件解决：
三个参数：按时间滚动，按大小128M滚动，禁止按个数滚动，设置为0
```

### 17、flume的拦截器

```
etl:验证是否是字符串
时间：昨天数据发动到flume sink时已经是第二天的数据，这时需要定义拦截器修改时间

自定义拦截器步骤：
实现interceptor接口，重写4个方法：初始化，单个event的处理逻辑，多个event的处理逻辑，关闭，实现静态内部类Interceptor.Builder类
打包上传到flume/lib目录下，同时在配置文件中国定义全类名$Builder
```

### 18、flume的选择器

```
replicating:无差别发送所有channel
multiplexing:选择性发送
```

### 19、flume的监控器

```
使用ganglia:
监控：尝试次数和成功次数的比例
如果尝试次数远远大于成功次数，需要解决问题：
1、设置内存4-6G(默认是2000M);在flume-env.sh尽量与堆内存设置保持一致，避免频繁的fullgc
2、增加节点
```

### 20、flume的优化

```
1、file channel尽量设置多磁盘，

2、hdfs sink需要设置滚动写入的频率，避免小文件

3、增大内存，扩充节点
```

### 21、kafka的组成

```
1、生产者，消费者，broker，zk(消费者，broker的id)

2、压测时，2 *(生产者峰值生产速率 * 副本2 / 100) + 1得到集群台数，一般是边压测，边调整集群台数，刚开始设置3台压测

3、副本数选择：2-3，

4、数据量估计：100万的日活，100条每个人每天，大约一天100G数据，平均速率大约是1150条/s，约1-2M/s,峰值估计值为20-50M/s

5、磁盘空间估计：100G * 副本2 * 3天 / 0.7系数

6、分区数确定：目标吞吐量t=100M/s,根据一个分区时的压测数据：生产峰值速率tp,消费峰值速率tc,则分区数估计值为t / min(tp,tc)

```

### 22、kafka的分区分配策略

```
range:3个消费者消费10个分区，会按顺序4,3,3消费，容易造成负载不均衡

roundrobin:会将所有分区轮询的方式分配给每一个消费者，能够解决负载不均衡的方式
```

### 23、kafka中isr和hw

```
isr:集群中同步的broker
hw:集群中最大offset中的最小值
leo:集群中的最大offset
```

### 24、kafka中的ack

```
0:无应答
1:leader应答
-1:leader和follower全部应答

0:不用，1：会丢失数据，所以普通日志可以使用，-1，会有重复数据，加上事务和幂等性可以实现精准一次性消费，金融相关的可以使用，效率很低
```

### 25、kafka消费者的offset

```
之前维护在zk中，后来维护在kafka内部一个默认topic中consumer中
```

### 26、kafka优化

```
1、减小保存数据的天数，默认7天，设置为3天，12小时等

2、减小副本数，2个

3、增大通信时间，防止网络抖动导致的副本的多次复制

4、针对单个日志超过1M的需要特殊设置，可消费<可复制

5、内存大小设置从1G设置为6G
```

### 27、hive和mysql的区别

```
1、相同点都能对数据写SQL分析

2、不同点：hive是单纯的分析工具，不是数据库，没有自己的引擎,而MySQL有自己的引擎

3、hive适合数据量巨大时的分析分析计算，而mysql适合数据量不是很大时分析计算

4、hive是维度建模的基础，能够对多数据源解析成表格，MySQL关系型数据库，符合3范式
```

### 28、hive架构

```
jdbc +
解析器，编译器，优化器，执行器 +
执行引擎：spark mr tez
```

### 29、hive内部表和外部表

```
源数据 + 元数据

内部表：删除数据时两个都删除
外部表：删除数据时仅仅删除元数据

元数据存放位置：mysql;做成高可用，防止元数据挂掉
```

### 30、hive中order by和sort by + distribut by 还有cluster by

```
order by 全局排序，尽量不用
换用sort by 排序 distribut by 分区解决
默认升序的话可以用cluster by
```

### 31、hive系统函数

```
日期：
date_add('2019-12-01',n) 得到日期后n天
date_sub('2019-12-01',n) 得到日期前n天
datediff('2019-12-08','2019-12-01') 得到日期的差值

next_day('2019-12-01',1)下一周的周日

last_day('2019-12-01') 一个月最后一天

substr(s,1,2) 获取前两个字符

get_json_object 解析json
```

### 32、hive自定义udf

```
继承：
重写：初始化，process，关闭
```

### 33、hive优化

```
1、jvm重用
2、combinehiveinputformat
3、提前merge
4、启用压缩：snappy
5、列式存储
6、预聚合：combiner
7、优化切片大小：max(0,min(块大小，long.max_value)) 通过调整0处的参数设置最大值，通过设置long.max_value处的参数，可以设置较小值，通过调整获取不同的map数
```

### 34、hive数据倾斜

```
1、空值检查
2、reduce数量是否不够
3、数据类型是否不匹配
```

### 35、sqoop的null值处理

```
hive中\N表示空值，MySQL中使用null表示空值

导出时使用：input-null-string和input-null-non-string
导入时使用：null-string 和 null-non-string
```

### 36、sqoop一致性问题

```
使用辅助表的方式解决：
在导入MySQL过程中可能会失败，因为导入中途可能因为某种原因导致宕机，会产生重复数据，或者直接失败，这个时候可以指定辅助表，导入到辅助表中，然后直接在一个事务中将数据导入到目标中
-staging-table
```

### 37、sqoop数据量

```
100万日活 ->转换成10万订单，1G数据
```

### 38、sqoop导数据时的时间

```
00:30分  40-50分钟
```

### 39、sqoop执行参数

```
--connect
--root
--123456
--target-dir
--delete-target-dir
--compress
--null
--feilds-terminated-by
```

### 40、sqoop的数据倾斜

```
1、通过rownum()生成均匀分布的字段
2、然后指定为分割字段，split-by某一列，将表切分成很多分割单元
3、启动num-mappers 启动多个map处理，默认是4个
```

### 41、sqoop的数据格式

```
1、hive中创建临时表，数据格式是text
2、ads层建表时直接使用text数据格式
```

### 42、azkaban相关

```
100-200个指标，
挂了重新跑
```

### 43、数仓版本

```
Apache 运维困难
cdh6.3.2 国内最多
hdp2.7 不够稳定，国内较少

cdp7.0

hadoop 2.7.2
flume 1.7.0
kafka 0.11.0.2
sqoop 1.4.6
mysql 5.6.24
azkaban 2.5.0
zookeeper 3.4.10
presto
java 1.8
spark 2.4.5

```

### 44、服务器选择

```
云服务器

物理机
```

### 45、集群部署

```
客户端尽量部署在一两个节点，核心占内存的部分尽量分布在不同节点

集群中flume是消费到hdfs的节点
日志服务器上会有flume，不属于集群
```

### 46、