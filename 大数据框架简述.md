# 大数据框架简述

#### HDFS（Hadoop分布式文件系统）

HDFS（Hadoop Distributed File System）源自于Google的GFS论文，发表于2003年10月，HDFS是GFS克隆版。是Hadoop体系中数据存储管理的基础。它是一个高度容错的系统，能检测和应对硬件故障，用于在低成本的通用硬件上运行。HDFS简化了文件的一致性模型，通过流式数据访问，提供高吞吐量应用程序数据访问功能，适合带有大型数据集的应用程序。

Client：切分文件；访问HDFS；与NameNode交互，获取文件位置信息；与DataNode交互，读取和写入数据。

NameNode：Master节点，在hadoop1.X中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户端请求。

DataNode：Slave节点，存储实际的数据，汇报存储信息给NameNode。

Secondary NameNode：辅助NameNode，分担其工作量；定期合并fsimage和fsedits，推送给NameNode；紧急情况下，可辅助恢复NameNode，但Secondary NameNode并非NameNode的热备。

#### YARN（Yet Another Resource Negotiator）

YARN是一种 Hadoop 资源管理器，它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。

ResourceManager

 

处理客户端请求

启动/监控ApplicationMaster

监控NodeManager

资源分配与调度

 

 

 

NodeManager

 

单个节点上的资源管理

处理来自ResourceManager的命令

处理来自ApplicationMaster的命令

 

 

 

ApplicationMaster

数据切分

为应用程序申请资源，并分配给内部任务

任务监控与容错

 

#### 运行在YARN上的计算框架

·    离线计算框架：MapReduce

·    DAG计算框架：Tez

·    流式计算框架：Storm

·    内存计算框架：Spark

·    图计算框架：Giraph、GraphLib

#### 分布式计算的思想

·    JobTracker：Master节点，只有一个，管理所有作业，作业/任务的监控、错误处理等；将任务分解成一系列任务，并分派给TaskTracker。

·    TaskTracker：Slave节点，运行Map Task和Reduce Task；并与JobTracker交互，汇报任务状态。

·    Map Task：解析每条数据记录，传递给用户编写的map(),并执行，将输出结果写入本地磁盘(如果为map-only作业，直接写入HDFS)。

·    Reducer Task：从Map Task的执行结果中，远程读取输入数据，对数据进行排序，将数据按照分组传递给用户编写的reduce函数执行。

#### Hive（基于Hadoop的数据仓库）系统结构

●元数据存储(Metastore)

●驱动(Driver)

●查询编译器(Query C ompiler)

●执行引擎(Execution Engine)

●服务器(HiveServer)

●客户端组件

●可扩展接口部分

Hive由facebook开源，最初用于解决海量结构化的日志数据统计问题。Hive定义了一种类似SQL的查询语言(HQL),将SQL转化为MapReduce任务在Hadoop上执行，通常用于离线分析。

#### Zookeeper（分布式协作服务）

源自Google的Chubby论文，发表于2006年11月，Zookeeper是Chubby克隆版
 解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。

#### HBase（分布式列存数据库）

Hbae源自Google的Bigtable论文，发表于2006年11月，HBase是Google Bigtable克隆版。HBase是一个针对结构化数据的可伸缩、高可靠、高性能、分布式和面向列的动态模式数据库。和传统关系数据库不同，HBase采用了BigTable的数据模型：增强的稀疏排序映射表（Key/Value），其中，键由行关键字、列关键字和时间戳构成。HBase提供了对大规模数据的随机、实时读写访问，同时，HBase中保存的数据可以使用MapReduce来处理，它将数据存储和并行计算完美地结合在一起。

HBase和Hive在大数据架构中处在不同位置，HBase主要解决实时数据查询问题，Hive主要解决数据处理和计算问题，一般是配合使用。

#### Sqoop（数据同步工具）

Sqoop是SQL-to-Hadoop的缩写，主要用于传统数据库和Hadoop之前传输数据。数据的导入和导出本质上是Mapreduce程序，充分利用了MR的并行化和容错性。

#### Pig（基于Hadoop的数据流系统）

由yahoo!开源，设计动机是提供一种基于MapReduce的ad-hoc(计算在query时发生)数据分析工具。其定义了一种数据流语言—Pig Latin，将脚本转换为MapReduce任务在Hadoop上执行，通常用于进行离线分析。

#### Spark

Spark是UC Berkeley AMPLab开发的是一种计算框架，分布式资源工作交由集群管理软件（Mesos、YARN） 。

特点：

先进架构

Spark采用Scala语言编写，底层采用了actor model的akka作为通讯框架，代码十分简洁高效。基于DAG图的执行引擎，减少多次计算之间中间结果写到Hdfs的开销。建立在统一抽象的RDD（分布式内存抽象）之上,使得它可以以基本一致的方式应对不同的大数据处理场景。

高效

提供Cache机制来支持需要反复迭代的计算或者多次数据共享，减少数据读取的IO开销。与Hadoop的MapReduce相比，Spark基于内存的运算比MR要快100倍；而基于硬盘的运算也要快10倍！

易用

Spark提供广泛的数据集操作类型（20+种），不像Hadoop只提供了Map和Reduce两种操作。Spark支持Java，Python和Scala API，支持交互式的Python和Scala的shell。

提供整体解决方案

以其RDD模型的强大表现能力，逐渐形成了一套自己的生态圈，提供了full-stack的解决方案。主要包括Spark内存中批处理，Spark SQL交互式查询，Spark Streaming流式计算， GraphX和MLlib提供的常用图计算和机器学习算法。

与Hadoop无缝连接

Spark可以使用YARN作为它的集群管理器

读取HDFS,HBase等一切Hadoop的数据

以上便是对Hadoop、Spark的一些浅显的介绍。事实上，解决大数据处理相关的问题，往往要经过数据收集（Flume、Kafka、Sqoop）、数据存储（HDFS、HBase）、资源管理（YARN）、计算（MapReduce、Spark）、数据分析（Pandas、NumPy、R）、数据可视化（Echart、Tableau）等环节。各个环节都有其相应的工具，Hadoop和Spark就是大数据处理流程中非常常用的两个框架。